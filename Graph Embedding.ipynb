{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "6ZsoPGoqefyk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywTMopcd6EMi"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from karateclub import NetMF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Graph Embedding Features"
      ],
      "metadata": {
        "id": "4vaYOADzei7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now after we have done creating our sorted graph we are ready to use this graph inside KarateClub library to get geometric graph embedding for each node, specifically we shall use NetMF embedding algorithm with 32 embedding space for each node, for the node that does not show in our train graph due to splitting and negative edges creating, we shall drop those rows from our data."
      ],
      "metadata": {
        "id": "6lDXCkAEer5q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp9NWTFuwgOh"
      },
      "outputs": [],
      "source": [
        "# reading sorted graph we have created previously\n",
        "sorted_graph = nx.read_gpickle(\"Data/sorted_graph.gpickle\")\n",
        "\n",
        "# reading train graph we to get base and refelction nodes\n",
        "train_graph = nx.read_edgelist(\"Data/train graph.csv\", comments = 's', create_using = nx.DiGraph(), nodetype = int, delimiter = \",\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_nodes = dict()\n",
        "reflection = dict()\n",
        "\n",
        "i = 0\n",
        "for node in train_graph.nodes():\n",
        "  base_nodes[i] = node\n",
        "  reflection[node] = i\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "Ktu7i91-jJ4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NetMF(32, 100, 2)\n",
        "model.fit(sorted_graph)\n",
        "# get embedding\n",
        "embedding = model.get_embedding()\n",
        "# save embedding file\n",
        "np.save(\"Data/NetMF_embed.npy\", embedding)"
      ],
      "metadata": {
        "id": "xECj7lAbate_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading org_train data frame who include only source node, destination node and the label\n",
        "org_train = pd.read_csv(\"Data/org_train.csv\")\n",
        "org_test = pd.read_csv(\"Data/org_test.csv\")\n",
        "org_valid = pd.read_csv(\"Data/org_valid.csv\")"
      ],
      "metadata": {
        "id": "tX2LN5HPYaDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEAdj1PVToyA"
      },
      "outputs": [],
      "source": [
        "def get_embedding(df):\n",
        "  \"\"\"\n",
        "  Return the embedding of df dataframe using graph embedding algorithm\n",
        "  Args: df ====> the dataframe we are processing\n",
        "  Return three arrays: source_embedding, destination_embedding, removed indices\n",
        "  \"\"\"\n",
        "  val = df.values\n",
        "  # save the removed index for excecluding those laters\n",
        "  removed = []\n",
        "  source_embedding = []\n",
        "  destination_embedding = []\n",
        "  \n",
        "  for index, row in enumerate(tqdm.tqdm(val)):\n",
        "    try:\n",
        "      # get the embedding of the refelction of current node\n",
        "      x = embedding[reflection[row[0]]]\n",
        "      y = embedding[reflection[row[1]]]\n",
        "      source_embedding.append(x)\n",
        "      destination_embedding.append(y)\n",
        "    except:\n",
        "      removed.append(index)\n",
        "      continue\n",
        "  \n",
        "  return source_embedding, destination_embedding, removed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get train embedding\n",
        "train_source_embedding, train_destination_embedding, train_removed = get_embedding(org_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb1mIX5ZcwKs",
        "outputId": "3bb1959f-67e2-4bd1-8171-e9f559626f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16798783/16798783 [00:57<00:00, 293521.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get test embedding\n",
        "test_source_embedding, test_destination_embedding, test_removed = get_embedding(org_test)"
      ],
      "metadata": {
        "id": "K7uU4dUEhwlU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75730669-96a5-46c8-995f-973ba21282b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1567572/1567572 [00:09<00:00, 165041.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get validation embedding\n",
        "valid_source_embedding, valid_destination_embedding, valid_removed = get_embedding(org_valid)"
      ],
      "metadata": {
        "id": "p2o1Su8ghy7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5683676a-ae2b-4e42-f9e0-b62d6ab2795e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 508683/508683 [00:01<00:00, 271355.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting result list to Numpy array\n",
        "train_source_embedding = np.array(train_source_embedding)\n",
        "train_destination_embedding = np.array(train_destination_embedding)\n",
        "train_removed = np.array(train_removed)"
      ],
      "metadata": {
        "id": "2a5Q2hFArTCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting result list to Numpy array\n",
        "test_source_embedding = np.array(test_source_embedding)\n",
        "test_destination_embedding = np.array(test_destination_embedding)\n",
        "test_removed = np.array(test_removed)"
      ],
      "metadata": {
        "id": "anClmr-GiPWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting result list to Numpy array\n",
        "valid_source_embedding = np.array(valid_source_embedding)\n",
        "valid_destination_embedding = np.array(valid_destination_embedding)\n",
        "valid_removed = np.array(valid_removed)"
      ],
      "metadata": {
        "id": "DSZYECE5q-Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIkIABD5ULv9"
      },
      "outputs": [],
      "source": [
        "# Merging train embedding into one Numpy array\n",
        "train_embedding = np.hstack((train_source_embedding, train_destination_embedding))\n",
        "# Merging test embedding into one Numpy array\n",
        "test_embedding = np.hstack((test_source_embedding, test_destination_embedding))\n",
        "# Merging validation embedding into one Numpy array\n",
        "valid_embedding = np.hstack((valid_source_embedding, valid_destination_embedding))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving embedding files\n",
        "np.save(\"Data/train_embedding\", train_embedding)\n",
        "np.save(\"Data/test_embedding\", test_embedding)\n",
        "np.save(\"Data/valid_embedding\", valid_embedding)"
      ],
      "metadata": {
        "id": "p5U_506UeRWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving removed indices files\n",
        "np.save(\"Data/train_removed\", train_removed)\n",
        "np.save(\"Data/test_removed\", test_removed)\n",
        "np.save(\"Data/valid_removed\", valid_removed)"
      ],
      "metadata": {
        "id": "m82YN-bvfDFr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6ZsoPGoqefyk"
      ],
      "name": "Graph Embedding.ipynb",
      "provenance": [],
      "mount_file_id": "1bFtlE8ZtgCAlPXRIeMfIHZ3Vne_t5LjD",
      "authorship_tag": "ABX9TyNGwY6ZsSLoAVOlBR/czqb4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}