{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGsPT3L4neqz"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpDcGNG1H-Wb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import shutil\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3--rgFs_CvE8"
      },
      "source": [
        "# Similarity Based Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDSE_BqPC0F8"
      },
      "source": [
        "This is the first part of designing graph features, at the first stage we will design similarit based features then we will design other type of features.\n",
        "\n",
        "**Similarity Features** which mainly focus on the topological structure of the graph, are the most straightforward and oldest link prediction metrics. These methods try to figure the missing links out by assigning similarity score, s(vx;vy), between node pairs (vx and vy) using the structural property of the graphs.\n",
        "\n",
        "Similarity-based methods consist of the three types:\n",
        "\n",
        "1.   Local Similarity-Based Approaches.\n",
        "2.   Global Similarity-Based Approaches.\n",
        "3.   Quasi-Local Similarity-Based Approaches.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dihje_qIEMvY"
      },
      "source": [
        "For Local Similarity-Based Approaches we will implement the following indices:\n",
        "\n",
        "1.   Source Node Incoming\n",
        "2.   Source Node Outcoming\n",
        "3.   Destination Node Incoming\n",
        "4.   Destination Node Outcoming\n",
        "5.   Outcoming Intersection\n",
        "6.   Incoming Intersection\n",
        "1.   Common Neighbors\n",
        "1.   Jaccard Index (JC)\n",
        "2.   Salton Index (SL)\n",
        "3.   SÃ¸rensen Index (SI)\n",
        "4.   Preferential Attachment Index (PA)\n",
        "5.   Adamic-Adar Index (AA)\n",
        "7.   Hub Promoted Index (HP)\n",
        "8.   Hub Depressed Index (HD)\n",
        "9.   Leicht-Holme-Newman Index (LHN)\n",
        "10.  Local Affinity Structure Index (LAS)\n",
        "11.  CAR-Based Index (CAR)\n",
        "12.  The Individual Attraction Index (IA)\n",
        "13.  Functional Similarity Weight (FSW)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT6UycFokBmA"
      },
      "source": [
        "Common Neighbors is one of the most extensive information retrieval metrics for link prediction tasks, due to its high efficiency, despite\n",
        "its simplicity. The idea behind CN is very intuitive; the probability of being linked for two nodes in the future is affected by the number of their common neighboring nodes, i.e., two nodes will highly probably establish a link if they have more shared nodes, It should be noted that the resulting score using CN is not normalized, and only shows the relative similarity of different node-pairs by considering shared nodes between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbMRw7NuEbfR"
      },
      "source": [
        "## Source / Destination Degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZBXvdQTcL8u"
      },
      "outputs": [],
      "source": [
        "def get_degree(df):\n",
        "  \"\"\"\n",
        "  Return incoming and outcoming degree of given dataframe\n",
        "  This function would return two numbers the first one for outcoming degree and the second for incoming degree\n",
        "  \"\"\"\n",
        "  out_degree, in_degree = [], []\n",
        "  \n",
        "  for i in df:\n",
        "      try:\n",
        "        out_degree.append(train_graph.out_degree(i))\n",
        "      except:\n",
        "        out_degree.append(0)\n",
        "  \n",
        "  for i in df:\n",
        "      try:\n",
        "        in_degree.append(train_graph.in_degree(i))\n",
        "      except:\n",
        "        in_degree.append(0)\n",
        "  \n",
        "  return out_degree, in_degree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxnSFlf0EhLX"
      },
      "source": [
        "## Intersection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5zEy5oVb87I"
      },
      "outputs": [],
      "source": [
        "def get_intersection(source, destination):\n",
        "  \"\"\"\n",
        "  Return incoming and outcoming intersection between source and destination nodes for a given dataframe\n",
        "  This function would return two lists the first one for outcoming intersection and the second for incoming intersection\n",
        "  \"\"\"\n",
        "\n",
        "  outcoming_intersection, incoming_intersection = [], []\n",
        "  \n",
        "  for node1, node2 in zip(source, destination):\n",
        "    try:\n",
        "      source_out = set(train_graph.successors(node1))\n",
        "      destination_out = set(train_graph.successors(node2))\n",
        "      outcoming_intersection.append(len(source_out.intersection(destination_out)))\n",
        "    \n",
        "    except:\n",
        "      outcoming_intersection.append(0)\n",
        "\n",
        "  for node1, node2 in zip(source, destination):\n",
        "    try:\n",
        "      source_in = set(train_graph.predecessors(node1))\n",
        "      destination_in = set(train_graph.predecessors(node2))\n",
        "      incoming_intersection.append(len(source_in.intersection(destination_in)))\n",
        "    \n",
        "    except:\n",
        "      incoming_intersection.append(0)\n",
        "  \n",
        "  return outcoming_intersection, incoming_intersection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig67qEUJLOTf"
      },
      "outputs": [],
      "source": [
        "# This implementation contains seperable code for each incoming and outcoming degree\n",
        "# # AS common neigbhors is not implemented for directed graph\n",
        "# # I will implement it using two function: common followers and common followee\n",
        "\n",
        "# def common_followee(source, destination):\n",
        "#   \"\"\"\n",
        "#   Define first part of common neigbhors index\n",
        "#   \"\"\"\n",
        "  \n",
        "#   try:\n",
        "#     if len(list(train_graph.successors(source))) == 0 or len(list(train_graph.successors(source))) == 0:\n",
        "#       return 0\n",
        "  \n",
        "#     source_followee = train_graph.successors(source)\n",
        "#     destination_followee = train_graph.successors(destination)\n",
        "\n",
        "#     return len(set(source_followee).intersection(set(destination_followee)))\n",
        "  \n",
        "#   except:\n",
        "#     return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1f8GH7V7oKz"
      },
      "outputs": [],
      "source": [
        "# def common_followers(source, destination):\n",
        "#   \"\"\"\n",
        "#   Define second part of common neigbhors index\n",
        "#   \"\"\"\n",
        "#   try:\n",
        "  \n",
        "#     if len(list(train_graph.predecessors(source))) == 0 or len(list(train_graph.predecessors(source))) == 0:\n",
        "#       return 0\n",
        "  \n",
        "#     source_followers = train_graph.predecessors(source)\n",
        "#     destination_followers = train_graph.predecessors(destination)\n",
        "\n",
        "#     return len(set(source_followers).intersection(set(destination_followers)))\n",
        "  \n",
        "#   except:\n",
        "#     return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygjfpVoWEvWF"
      },
      "source": [
        "## Jaccard Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhM-rXw_kcko"
      },
      "source": [
        "Jaccard Index not only takes the number of common nodes into account as in CN, but it also normalizes it by considering the total set of numbers of shared and non-shared neighbors, hence it can be used to compair to result togeather, as it is define for neigbhoors in general for undirected graph I shall split this metric into two parts as with the most of the rest metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaccard For Outcoming"
      ],
      "metadata": {
        "id": "1uFLwYgUjl-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP2qALoVGGKC"
      },
      "outputs": [],
      "source": [
        "def jaccard_for_outcoming(source, destination):\n",
        "  \n",
        "  \"\"\"\n",
        "  Calculate jaccard index for followee\n",
        "  source      ====> source nodes\n",
        "  destination ====> destination node\n",
        "  \"\"\"\n",
        "\n",
        "  try: \n",
        "    if train_graph.out_degree(source) == 0 or train_graph.out_degree(destination) == 0:\n",
        "      return 0\n",
        "\n",
        "    intersection = set(train_graph.successors(source)).intersection(set(train_graph.successors(destination)))\n",
        "    union = set(train_graph.successors(source)).union(set(train_graph.successors(destination)))\n",
        "    \n",
        "    return len(intersection) / len(union)\n",
        "  \n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaccard For Incoming"
      ],
      "metadata": {
        "id": "f19LeCp0jq_A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq_a98-0IBHP"
      },
      "outputs": [],
      "source": [
        "def jaccard_for_incoming(source, destination):\n",
        "  \n",
        "  \"\"\"\n",
        "  Calculate jaccard index for followers\n",
        "  source      ====> source nodes\n",
        "  destination ====> destination node\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    if train_graph.in_degree(source) == 0 or train_graph.in_degree(destination) == 0:\n",
        "      return 0\n",
        "\n",
        "    intersection = set(train_graph.predecessors(source)).intersection(set(train_graph.predecessors(destination)))\n",
        "    union = set(train_graph.predecessors(source)).union(set(train_graph.predecessors(destination)))\n",
        "    \n",
        "    return len(intersection) / len(union)\n",
        "  \n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N5Th2BgE0bC"
      },
      "source": [
        "## Salton Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HgIRH1jlNK2"
      },
      "source": [
        "Salton Index is also known as cosine similarity. It calculates the cosine angle between the two columns of the adjacency matrix and it is identified as the ratio of the number of shared neighbors of vx and vy to the square root of inner-product of their degrees."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Salton For Outcoming"
      ],
      "metadata": {
        "id": "BGOiMHRKj36a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_o5YtzuIU0m"
      },
      "outputs": [],
      "source": [
        "def salton_for_outcoming(source, destination):\n",
        "  \"\"\"\n",
        "  Calculate Salton Index for outcoming edges, this index also known as cosine distance and defined as:\n",
        "  Number of common followee / square root of (number of followee of soruce times number of followee of destination)\n",
        "  \"\"\"\n",
        "  try:\n",
        "    source_out = train_graph.out_degree(source)\n",
        "    destination_out = train_graph.out_degree(destination)\n",
        "    if source_out == 0 or  destination_out == 0:\n",
        "      return 0\n",
        "\n",
        "    numerator = len(set(train_graph.successors(source)).intersection(set(train_graph.successors(destination))))\n",
        "    denominator = (source_out * destination_out) ** 0.5\n",
        "    \n",
        "    return numerator / denominator\n",
        "  \n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Salton For Incoming"
      ],
      "metadata": {
        "id": "aTmRNnxtj7Xt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnTQBdVdPSNt"
      },
      "outputs": [],
      "source": [
        "def salton_for_incoming(source, destination):\n",
        "  \n",
        "  \"\"\"\n",
        "  Calculate Salton Index for incoming edges, this index also known as cosine distance and defined as:\n",
        "  Number of common followers / square root of (number of followers of soruce times number of followers of destination)\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    source_in = train_graph.in_degree(source)\n",
        "    destination_in = train_graph.outin_degree(destination)\n",
        "    if source_in == 0 or  destination_in == 0:\n",
        "      return 0\n",
        "\n",
        "    numerator = len(set(train_graph.predecessors(source)).intersection(set(train_graph.predecessors(destination))))\n",
        "    denominator = (source_in * destination_in) ** 0.5\n",
        "    \n",
        "    return numerator / denominator\n",
        "  \n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjB0kVxcE6Mx"
      },
      "source": [
        "## Sorensen Index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sorensen For Outcoming"
      ],
      "metadata": {
        "id": "gFzAZvi7kAA7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq9jUpaR7_Js"
      },
      "outputs": [],
      "source": [
        "def sorensen_for_outcoming(source, destination):\n",
        "  \"\"\"\n",
        "  Define sorensen index of nodes who source and destination nodes follow\n",
        "  \"\"\"\n",
        "  try:\n",
        "    source_out = train_graph.out_degree(source)\n",
        "    destination_out = train_graph.out_degree(destination)\n",
        "    if source_out == 0 or destination_out == 0:\n",
        "      return 0\n",
        "\n",
        "    numerator = len(set(train_graph.successors(source)).intersection(set(train_graph.successors(destination))))\n",
        "    denominator = source_out + destination_out\n",
        "    \n",
        "    return numerator / denominator\n",
        "  \n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sorensen For Incoming"
      ],
      "metadata": {
        "id": "4Y6A0rqjkC-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhJcz0Xq7_M7"
      },
      "outputs": [],
      "source": [
        "def sorensen_for_incoming(source, destination):\n",
        "  \"\"\"\n",
        "  Define sorensen index of nodes who follow source and destination nodes\n",
        "  \"\"\"\n",
        "  try:\n",
        "    source_in = train_graph.in_degree(source)\n",
        "    destination_in = train_graph.in_degree(destination)\n",
        "    if source_in == 0 or  destination_in == 0:\n",
        "      return 0\n",
        "\n",
        "    numerator = len(set(train_graph.predecessors(source)).intersection(set(train_graph.predecessors(destination))))\n",
        "    denominator = source_out + destination_out\n",
        "    \n",
        "    return numerator / denominator\n",
        "  \n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvq86rIpmNOD"
      },
      "source": [
        "New nodes joining the network are more likely to connect with the nodes with higher connections (hub) than the nodes with lower degrees, hence the result would be larger in this way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6bCdoFLFCJg"
      },
      "source": [
        "## Preferential Attachment Index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preferential Attachment For Outcoming"
      ],
      "metadata": {
        "id": "sRMFlZJtkLFO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVBraMqy80if"
      },
      "outputs": [],
      "source": [
        "# This index is implementd in NetworkX for undirected graph only\n",
        "# For that i will implement it using two parts for incoming and for outcoming\n",
        "\n",
        "def outcoming_preferential_attachment(source, destination):\n",
        "  \"\"\"\n",
        "  Implementing Preferential Attachmen Index of nodes who source and destination nodes follow\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    source_out = train_graph.out_degree(source)\n",
        "    destination_out = train_graph.out_degree(destination)\n",
        "    \n",
        "    if source_out == 0 or destination_out == 0:\n",
        "      return 0\n",
        "\n",
        "    return source_out * destination_out\n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preferential Attachment For Incoming"
      ],
      "metadata": {
        "id": "_Op5EP_GkN6V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36JLkE_X-2XS"
      },
      "outputs": [],
      "source": [
        "def incoming_preferential_attachment(source, destination):\n",
        "  \"\"\"\n",
        "  Implementing Preferential Attachmen Index of nodes who follow source and destination nodes\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    source_in = train_graph.in_degree(source)\n",
        "    destination_in = train_graph.in_degree(destination)\n",
        "    \n",
        "    if source_in == 0 or destination_in == 0:\n",
        "      return 0\n",
        "\n",
        "    return source_in * destination_in\n",
        "  except:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxOZMBv9FH4L"
      },
      "source": [
        "## Adamic Adar Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4PFBFLlDVmh"
      },
      "source": [
        "Lada Adamic and Eytan Adar index is defined by inverted sum of degrees of common neighbours for given two vertices as follow:\n",
        "$$A(x,y)=\\sum_{u \\in N(x) \\cap N(y)}\\frac{1}{log(|N(u)|)}$$\n",
        "\n",
        "We take intersection between two nodes, foreach node in interseaction u if it's neighbours large then it's chance to be a famous person or celebrity is high so no mean of x and y following each other (they follow the same famous person without knowing each other), if neighbours of u is small them there is high chance to x and y someone to follow the other or both.\n",
        "\n",
        "**Note 1**: log is a monotonic function, in the formula we use it to reduce the impact so we don't divide by very big number of very small number.\n",
        "\n",
        "**Note 2**: Adamic Adar index is defined for undirected graph, here we shall modifed it to fit with directed graph so we use it for same nodes followed by our two nodes soruce and destination nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIOkKnTBAhVR"
      },
      "outputs": [],
      "source": [
        "def adamic_adar(source, destination):\n",
        "  \"\"\"\n",
        "  Define Adamic Adar index for Directed Graph using only the nodes that source and destination nodes follow\n",
        "  this implementation shall not consider nodes who follow source node and destination node\n",
        "  \"\"\"\n",
        "  \n",
        "  # define dictionary to hold number of nodes for a visited node\n",
        "  # so we don't have to calculate it's neighbors many times\n",
        "  map = dict()\n",
        "  result = []\n",
        "  \n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    try:\n",
        "      # get the intersection between neighbors of source node and neighbors of destination node\n",
        "      nodes = list(set(train_graph.successors(source_node)).intersection(set(train_graph.successors(destination_node))))\n",
        "      \n",
        "      if len(nodes) != 0:\n",
        "        index = 0\n",
        "        for node in nodes:\n",
        "          \n",
        "          if node in map:\n",
        "            index += 1 / (map[node])\n",
        "          \n",
        "          else:\n",
        "            neighbor_count = train_graph.in_degree(node)\n",
        "            if neighbor_count == 0:\n",
        "              map[node] = 0\n",
        "            else:\n",
        "              neighbors = np.log10(neighbor_count)\n",
        "            map[node] = neighbors\n",
        "            index += 1 / neighbors\n",
        "        result.append(index)\n",
        "      \n",
        "      else:\n",
        "        result.append(0)\n",
        "    except:\n",
        "      result.append(0)\n",
        "  \n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9I3AAgmFNRI"
      },
      "source": [
        "## Hup Promoted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHKF2cjum9QX"
      },
      "source": [
        "HP is determined by the ratio of the number of common neighbors of both source and destination to the minimum of degrees of source and destination. Here, link formation between lower degree nodes and the hubs is more promoted, while the formation of the connection between hub nodes are demoted."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hup Prompted For Outcoming"
      ],
      "metadata": {
        "id": "BXRJWCwdkV3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHnsHPGZ0KBu"
      },
      "outputs": [],
      "source": [
        "def outcoming_hup_promoted(source, destination):\n",
        "\n",
        "  \"\"\"\n",
        "  Define Hup Promoted Index for outcoming edges or for nodes that source and destination follow\n",
        "  it defined as number of common successors over min number of successors between two nodes\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "\n",
        "    try:\n",
        "      \n",
        "      source_successors_len = train_graph.out_degree(source_node)\n",
        "      destination_successros_len = train_graph.out_degree(destination_node)\n",
        "\n",
        "      if source_successors_len == 0 or destination_successros_len == 0:\n",
        "        result.append(0)\n",
        "        continue\n",
        "  \n",
        "      numerator = len(set(train_graph.successors(source_node)).intersection(set(train_graph.successors(destination_node))))\n",
        "      denominator = min(source_successors_len, destination_successros_len)\n",
        "\n",
        "      result.append(numerator / denominator)\n",
        "  \n",
        "    except:\n",
        "      result.append(0)\n",
        "  \n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hup Prompted For Incoming"
      ],
      "metadata": {
        "id": "lyyfD45OkYt6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy0DUBCc1vGX"
      },
      "outputs": [],
      "source": [
        "def incoming_hup_promoted(source, destination):\n",
        "\n",
        "  \"\"\"\n",
        "  Define Hup Promoted Index for incoming edges or for nodes that follow source and destination\n",
        "  it defined as number of common predecessors over min number of predecessors between two nodes\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    try:\n",
        "\n",
        "      source_predecessors_len = train_graph.in_degree(source_node)\n",
        "      destination_predecessors_len = train_graph.in_degree(destination_node)\n",
        "\n",
        "      if source_predecessors_len == 0 or destination_predecessors_len == 0:\n",
        "        result.append(0)\n",
        "        continue\n",
        "  \n",
        "      numerator = len(set(train_graph.predecessors(source_node)).intersection(set(train_graph.predecessors(destination_node))))\n",
        "      denominator = min(source_predecessors_len, destination_predecessors_len)\n",
        "\n",
        "      result.append(numerator / denominator)\n",
        "\n",
        "    except:\n",
        "      result.append(0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7GPth46FT4v"
      },
      "source": [
        "## Hup Depressed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EmnfgrMnY_u"
      },
      "source": [
        "The totally opposite analogy of HP is also considered and it is determined by the ratio of the number of common neighbors of both source and destination to the maximum of degrees of source and destination. Here, the link formation between lower degree nodes and link formation between hubs is promoted. However, the connection between hub nodes and lower degree nodes are demoted."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hup Depressed For Outcoming"
      ],
      "metadata": {
        "id": "MT4vGZA0kdnE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSnk6WfA2iCL"
      },
      "outputs": [],
      "source": [
        "def outcoming_hup_depressed(source, destination):\n",
        "  \"\"\"\n",
        "  Define Hup Depressed Index for outcoming edges or for nodes that source and destination follow\n",
        "  it defined as number of common successors over max number of successors between two nodes\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "\n",
        "    try:\n",
        "      \n",
        "      source_successors_len = train_graph.out_degree(source_node)\n",
        "      destination_successros_len = train_graph.out_degree(destination_node)\n",
        "\n",
        "      if source_successors_len == 0 or destination_successros_len == 0:\n",
        "        result.append(0)\n",
        "        continue\n",
        "  \n",
        "      numerator = len(set(train_graph.successors(source_node)).intersection(set(train_graph.successors(destination_node))))\n",
        "      denominator = max(source_successors_len, destination_successros_len)\n",
        "\n",
        "      result.append(numerator / denominator)\n",
        "  \n",
        "    except:\n",
        "      result.append(0)\n",
        "  \n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hup Depressed For Incoming"
      ],
      "metadata": {
        "id": "OawsoLvkkhFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4IdeFWO2iFs"
      },
      "outputs": [],
      "source": [
        "def incoming_hup_depressed(source, destination):\n",
        "\n",
        "  \"\"\"\n",
        "  Define Hup Promoted Index for incoming edges or for nodes that follow source and destination\n",
        "  it defined as number of common predecessors over max number of predecessors between two nodes\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    try:\n",
        "\n",
        "      source_predecessors_len = train_graph.in_degree(source_node)\n",
        "      destination_predecessors_len = train_graph.in_degree(destination_node)\n",
        "\n",
        "      if source_predecessors_len == 0 or destination_predecessors_len == 0:\n",
        "        result.append(0)\n",
        "        continue\n",
        "  \n",
        "      numerator = len(set(train_graph.predecessors(source_node)).intersection(set(train_graph.predecessors(destination_node))))\n",
        "      denominator = max(source_predecessors_len, destination_predecessors_len)\n",
        "\n",
        "      result.append(numerator / denominator)\n",
        "\n",
        "    except:\n",
        "      result.append(0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnHy7RKmFZ8_"
      },
      "source": [
        "## Leicht Holme Newman Index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leicht Holme Newman For Outcoming"
      ],
      "metadata": {
        "id": "qwVru7-4knQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtPg1T_U21gG"
      },
      "outputs": [],
      "source": [
        "def outcoming_leicht(source, destination):\n",
        "  \"\"\"\n",
        "  Define Leicht Holme Newman Index of outcoming edges\n",
        "  it defined as number of intersection nodes over multiplication of length of each node from our two node's followee\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    try:\n",
        "      source_successors = train_graph.out_degree(source_node)\n",
        "      destination_successors = train_graph.out_degree(destination_node)\n",
        "      \n",
        "      if source_successors == 0 or destination_successors == 0:\n",
        "          result.append(0)\n",
        "          continue\n",
        "        \n",
        "      numerator = len(set(train_graph.successors(source_node)).intersection(set(train_graph.successors(destination_node))))\n",
        "      denominator = source_successors * destination_successors\n",
        "\n",
        "      result.append(numerator / denominator)\n",
        "    except:\n",
        "      result.append(0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leicht Holme Newman For Incoming"
      ],
      "metadata": {
        "id": "MM9i7VRCkrd2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0U10-m-3pVs"
      },
      "outputs": [],
      "source": [
        "def incoming_leicht(source, destination):\n",
        "  \"\"\"\n",
        "  Define Leicht Holme Newman Index of incoming edges\n",
        "  it defined as number of intersection nodes over multiplication of length of each node from our two node's followers\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    \n",
        "    try:\n",
        "      source_predecessors = train_graph.in_degree(source_node)\n",
        "      destination_predecessors = train_graph.in_degree(destination_node)\n",
        "      \n",
        "      if source_predecessors == 0 or destination_predecessors == 0:\n",
        "          result.append(0)\n",
        "          continue\n",
        "        \n",
        "      numerator = len(set(train_graph.predecessors(source_node)).intersection(set(train_graph.predecessors(destination_node))))\n",
        "      denominator = source_predecessors * destination_predecessors\n",
        "\n",
        "      result.append(numerator / denominator)\n",
        "\n",
        "    except:\n",
        "      result.append(0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DcIxjN8FplX"
      },
      "source": [
        "## Local Affinity Structure Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLHmfyBVn1se"
      },
      "source": [
        "Local Affinity Structure shows the affinity relationship between a pair of nodes and their common neighbors. The hypothesis is that a higher affinity of two nodes and their common neighbors increases the probability of getting connected."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Local Affinity Structure For Outcoming"
      ],
      "metadata": {
        "id": "7EUFNFW1ku7F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yyxul-13p1D"
      },
      "outputs": [],
      "source": [
        "def outcoming_local_affinity(source, destination):\n",
        "  \"\"\"\n",
        "  Define Local Affinity Structure Index for outcoming edges of our two nodes\n",
        "  This define as summing of two parts:\n",
        "  Part1 ========> Intersection of two node's successors over number of first node successors\n",
        "  Part2 ========> Intersection of two node's successors over number of second node successors\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    try:\n",
        "      source_successors = train_graph.out_degree(source_node)\n",
        "      destination_successors = train_graph.out_degree(destination_node)\n",
        "      \n",
        "      if source_successors == 0 or destination_successors == 0:\n",
        "          result.append(0)\n",
        "          continue\n",
        "        \n",
        "      numerator = len(set(train_graph.successors(source_node)).intersection(set(train_graph.successors(destination_node))))\n",
        "      metric = (numerator / source_successors) + (numerator / destination_successors)\n",
        "      result.append(metric)\n",
        "    except:\n",
        "      result.append(0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Local Affinity Structure For Incoming"
      ],
      "metadata": {
        "id": "DVWnVGnzk1UG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So0D5M8m7djd"
      },
      "outputs": [],
      "source": [
        "def incoming_local_affinity(source, destination):\n",
        "  \"\"\"\n",
        "  Define Local Affinity Structure Index for incoming edges of our two nodes\n",
        "  This define as summing of two parts:\n",
        "  Part1 ========> Intersection of two node's predecessors over number of first node predecessors\n",
        "  Part2 ========> Intersection of two node's predecessors over number of second node predecessors\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    try:\n",
        "      source_predecessors = train_graph.in_degree(source_node)\n",
        "      destination_predecessors = train_graph.in_degree(destination_node)\n",
        "      \n",
        "      if source_predecessors == 0 or destination_predecessors == 0:\n",
        "          result.append(0)\n",
        "          continue\n",
        "        \n",
        "      numerator = len(set(train_graph.successors(source_node)).intersection(set(train_graph.successors(destination_node))))\n",
        "      metric = (numerator / source_predecessors) + (numerator / destination_predecessors)\n",
        "      result.append(metric)\n",
        "    except:\n",
        "      result.append(0)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seB2zvQ0FyAi"
      },
      "source": [
        "## Car Based Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOvstyri-zaH"
      },
      "source": [
        "Car Based Index the consider second-level neighborhood which carries essential information regarding the topology of the network. Therefore, CAR filters these noises and considers nodes that are interlinked with neighbors mostly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LiQamLz7n4G"
      },
      "outputs": [],
      "source": [
        "def car_based_index(source, destination):\n",
        "  \"\"\"\n",
        "  Car-Based Index of source and destination nodes is similar to Adamic Adar as it defined as follow:\n",
        "  number of intersection nodes between our two nodes time number of incoming edges for each node in the intersection \n",
        "  \"\"\"\n",
        "  \n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    index = 0\n",
        "    \n",
        "    try:\n",
        "      nodes = list(set(train_graph.successors(source_node)).intersection(set(train_graph.successors(destination_node))))\n",
        "      \n",
        "      if len(nodes) != 0:\n",
        "        for node in nodes:\n",
        "          index += train_graph.in_degree(node) / 2\n",
        "        \n",
        "        result.append(len(nodes) * index)\n",
        "\n",
        "      else:\n",
        "        result.append(0)\n",
        "    \n",
        "    except:\n",
        "      result.append(0)\n",
        "  \n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwuzX2IiF603"
      },
      "source": [
        "## Individual Attraction Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK0HB0R5AVKV"
      },
      "outputs": [],
      "source": [
        "def individual_attraction(source, destination):\n",
        "  \"\"\"\n",
        "  Individual Attraction Index for outcoming edges is defined as follow:\n",
        "  Intersection between source and destination + 2 over the intersection times number of predecessors of each node in the neighbhoor\n",
        "  of source and destination togeather\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    index = 0\n",
        "    \n",
        "    try:\n",
        "      nodes = list(set(train_graph.successors(source_node)).intersection(set(train_graph.successors(destination_node))))\n",
        "      if len(nodes) != 0:\n",
        "        \n",
        "        for node in nodes:\n",
        "          index += (len(nodes) + 2) / ((len(nodes) * train_graph.in_degree(node)))\n",
        "        result.append(index)\n",
        "      \n",
        "      else:\n",
        "        result.append(0)\n",
        "      \n",
        "    except:\n",
        "      result.append(0)\n",
        "  \n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7RNyBpfoRKI"
      },
      "source": [
        "This index is first used in order to understand the similarity of physical or biochemical characteristics of proteins. Their motivation is based on the CzekanowskiâDice distance that is used in order to estimate the functional similarity of proteins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfUv6w-tGRWc"
      },
      "source": [
        "## Functional Similarity Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functional Similarity Weight For Outcoming"
      ],
      "metadata": {
        "id": "dJgDQ1A0k6yi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bUY9xR6Itvz"
      },
      "outputs": [],
      "source": [
        "def out_func_sim_weight(source, destination, average_degree):\n",
        "  \"\"\"\n",
        "  Functional Similarity Weight of outcoming edges which is defined as follow:\n",
        "  2 * number of intersection between source and destination \n",
        "  over number of diffrence between neighbors of source and neighbors of destination\n",
        "  plus two times number of intersection plus Beta\n",
        "  Beta is define as follow:\n",
        "  max(0, average neighbors of netowrk - number of diffrence + number of intersection )\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    \n",
        "    try:\n",
        "      if train_graph.successors(source_node) == 0 or train_graph.successors(destination_node) == 0:\n",
        "        result.append(0)\n",
        "        continue\n",
        "      \n",
        "      s1, s2 = set(train_graph.successors(source_node)), set(train_graph.successors(destination_node))\n",
        "      \n",
        "      numerator = len(s1.intersection(s2))\n",
        "      denominator = s1 - s2\n",
        "      beta = max(0, average_degree - len(denominator) + numerator)\n",
        "\n",
        "      result.append((((2 * numerator) / (len(denominator) + beta)) ** 2))\n",
        "        \n",
        "    except:\n",
        "      result.append(0)\n",
        "    \n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functional Similarity Weight For Incoming"
      ],
      "metadata": {
        "id": "tjQedaK3k_ys"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJigvw-8IpM2"
      },
      "outputs": [],
      "source": [
        "def in_func_sim_weight(source, destination, average_degree):\n",
        "  \"\"\"\n",
        "  Functional Similarity Weight of incoming edges which is defined as follow:\n",
        "  2 * number of intersection between source and destination \n",
        "  over number of diffrence between neighbors of source and neighbors of destination\n",
        "  plus two times number of intersection plus Beta\n",
        "  Beta is define as follow:\n",
        "  max(0, average neighbors of netowrk - number of diffrence + number of intersection )\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  for source_node, destination_node in zip(source, destination):\n",
        "    \n",
        "    try:\n",
        "      if train_graph.predecessors(source_node) == 0 or train_graph.predecessors(destination_node) == 0:\n",
        "        result.append(0)\n",
        "        continue\n",
        "      \n",
        "      s1, s2 = set(train_graph.predecessors(source_node)), set(train_graph.predecessors(destination_node))\n",
        "      \n",
        "      numerator = len(s1.intersection(s2))\n",
        "      denominator = s1 - s2\n",
        "      beta = max(0, average_degree - len(denominator) + numerator)\n",
        "\n",
        "      result.append((((2 * numerator) / (len(denominator) + beta)) ** 2))\n",
        "        \n",
        "    except:\n",
        "      result.append(0)\n",
        "    \n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX-2psggON2v"
      },
      "source": [
        "**Refrence**: Ece C. Mutlu et al, 2020, REVIEW ON LEARNING AND EXTRACTING GRAPH FEATURES FOR LINK PREDICTION."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KGsPT3L4neqz",
        "3--rgFs_CvE8",
        "AbMRw7NuEbfR",
        "LxnSFlf0EhLX",
        "ygjfpVoWEvWF",
        "1uFLwYgUjl-2",
        "f19LeCp0jq_A",
        "1N5Th2BgE0bC",
        "BGOiMHRKj36a",
        "aTmRNnxtj7Xt",
        "mjB0kVxcE6Mx",
        "gFzAZvi7kAA7",
        "4Y6A0rqjkC-1",
        "i6bCdoFLFCJg",
        "sRMFlZJtkLFO",
        "_Op5EP_GkN6V",
        "XxOZMBv9FH4L",
        "F9I3AAgmFNRI",
        "BXRJWCwdkV3T",
        "lyyfD45OkYt6",
        "M7GPth46FT4v",
        "MT4vGZA0kdnE",
        "OawsoLvkkhFU",
        "fnHy7RKmFZ8_",
        "qwVru7-4knQx",
        "MM9i7VRCkrd2",
        "4DcIxjN8FplX",
        "7EUFNFW1ku7F",
        "DVWnVGnzk1UG",
        "seB2zvQ0FyAi",
        "GwuzX2IiF603",
        "gfUv6w-tGRWc",
        "tjQedaK3k_ys"
      ],
      "name": "Generating Dataset.ipynb",
      "provenance": [],
      "mount_file_id": "1uPGnyQFKjBJ_hMQ4Q-L3opOwvhDqRPxh",
      "authorship_tag": "ABX9TyPC5Q8BeLVtaQrN498Nc2Dh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
